---
title: "AFMC We Need - Text Mining Project"
subtitle: "Interim Report to AFMC"
author: "Jason Freels"
date: "2/26/2020"
output: 
  html_document:
    df_print: "paged"
    toc: true
    toc_float: yes
    fig_cap: yes
---

```{r setup, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      comment = NA,
                      warning = F,
                      fig.align = "center")

quick <<- !TRUE
```

<style>
div.main-container {

    max-width: 2000px !important;

}

.nav-tabs>li>a {

    background-color: #337ab7;
    color: white;
    font-weight: bold;

}
    
.nav-tabs>li.active>a {

    background-color: white;
    color: #337ab7;
    font-weight: bold;

}
    
ul.nav.nav-tabs{

    margin-top: 50px !important;

}

p {

    font-size: 16pt !important;
    
}

ul {

    font-size: 14pt !important;
    
}

pre code {

    font-size: 14pt !important;
    
}

.grid-container {

    display: inline-grid;
    grid-template-columns: auto auto auto;
    padding: 0;
    
}
</style>

# Introduction 

## Background

The "AFMC We Need" effort surveyed the AFMC workforce to capture their responses on how best to improve the MAJCOM. This project aims to help AMFC analysts extract insights from this survey (along with other surveys) via a software package developed using the R statistical programming environment. This document demonstrates how an intended user would interact with the package to return a desired result.

- Generate visualizations
- Automate reports

## Assumptions

This demonstration assumes that the user has access to a machine on which the R programming environment and the RStudio integrated development environment (IDE) have been installed.  If this assumption is not met, the user may refer to the [AFIT Guide to R Programming](https://datasciencelabs.io/r-basics/) for detailed instructions on setting up their machine.

Furthermore, this document demonstrates package version `2020.04.04`.  This version makes the assumption that the data being analyzed (responses and other features) are stored in a row-column format.  It is expected that this assumption will be relaxed as result of analyzing different data types through future development efforts.

## Getting Started

Prior to using the `Text.Replace` package, the user must first ensure that it is installed on their machine.  This package has not yet been published to the main R package repository, the Comprehensive R Archive Network (the CRAN). Therefore, it cannot be installed from CRAN, but it can be installed from Github using the code shown in the chunk below

```{r, eval=FALSE}
# If the devtools package is not already installed
# the code below installs the package from the CRAN
if(!("devtools" %in% names(installed.packages()[,"Package"]))) {
  
   install.packages("devtools")
  
}

# With the devtools package now installed we can use it 
# to install the Text.Replace package from Github  
devtools::install_github("clawilso15/Text.Replace")
```

Once the package has been installed, the user needs to load it into their working environment so that the functions contained in the package are available for use. This can be done using the `library()` function. 

```{r}
library(Text.Replace)
```

In addition to the `Text.Replace` package, users wanting to replicate the results shown here will also need to install and load the following packages.

```{r, eval=FALSE}
# install packages
install.packages(c("quanteda","Matrix","DT"))
```

```{r}
# load packages
library("quanteda")
library("Matrix")
library("DT")
```

# Analysis

## Step 1: Extracting the Text

With the `Text.Replace` package installed and loaded, the user's first analysis step to is to extract the text data from the file in which it is contained. For this purpose the package includes the `extract_text()` function to ingest text data from files of the following types:

- Row-Column: .CSV, .XLS, .XLSX
- Tab Delimited: .TXT
- MS Word Files: .DOC, .DOCX
- PDF files
- Images Files: .PDF, .PNG, .TIF

This function is used as shown below. I've presented the first 100 rows of this data set as an interactive table.

```{r, eval=FALSE}
csv = "path/to/data/file.csv" 
DATA = Text.Replace::extract_text(csv)
DT::datatable(head(DATA, 100))
```

```{r, echo=FALSE}
csv = "C:\\Users\\Aubur\\github\\auburngrads\\afmc_we_need\\data\\AWNComment_Freels.csv"
DATA = Text.Replace:::extract_text(csv)
DT::datatable(head(DATA, 100))
```

## Step 2: Creating the document corpus

With the data extracted from the file, the next task is to convert the object `DATA` into one or more objects that will facilitate further analysis tasks.  The objects that we want are a corpus object and a document feature matrix (DFM).  The `Text.Replace` package contains the function `create_corpus()` to create a corpus object from an object containing the raw text data.  As currently implemented, this function presumes that the data are stored in a row-column format where each row (response) is considered to be a distinct document and each column contains a feature adding context to each document.  

To use this function, the user is required to provide 1) the raw data object and 2) the name of the column in which the the response text is stored. For the AFMC We Need data, the survey text responses are stored in the 'Comments' column, thus the function is used as shown below.

```{r}
AFMC_corpus = Text.Replace::create_corpus(DATA, "Comments")
```

Note that all other columns are treated as document variables (aka `docvars`). 
Printing `AFMC_corpus` shows that the corpus object contains `r nrow(DATA)` documents and `r ncol(DATA)-1` different document variables that describe these documents. 

```{r}
AFMC_corpus
```

## Step 3: Creating the document feature matrix

Next, we want to create a document feature matrix (DFM) from the corpus object. The DFM is the primary object that will be used to carry out our subsequent analysis tasks.  The `Text.Replace` package contains the `create_dfm()` function to create the document feature matrix.  The code in the chunk below shows the arguments for this function. 

```{r, cache=TRUE}
AFMC_dfm1 = Text.Replace:::create_dfm(AFMC_corpus, 
                                     num_ngrams = 1,
                                     remove_punct = T,
                                     tolower = TRUE, 
                                     stem = FALSE, 
                                     select = NULL, 
                                     remove = NULL, 
                                     dictionary = NULL, 
                                     thesaurus = NULL, 
                                     groups = NULL)
```

It's important to note the output object created by this function.  After reviewing AFMC analysts' prior work we noted that evaluating the responses word-by-word and as well as multi-word phrases is important. Therefore, this function returns a list containing a several DFM objects. The number of DFM objects contained in the list corresponds to the number of values provided in the `num_ngrams` argument.  In the example code above `num_ngrams = 6` thus, the function returned a list containing one DFM object pertaining only to 6-word phrases.  In the example code below, `num_ngrams = 1:6` (these are the integers 1-6) thus, the function returns a list containing six DFM objects wherein each DFM pertains to phrases with 1, 2, 3, 4, 5 or 6 words. Unsurprisingly, the code in the chunk below takes more time to execute and produces a large output object. 

```{r, cache=TRUE, eval=FALSE}
AFMC_dfm6 = Text.Replace:::create_dfm(AFMC_corpus,
                                     num_ngrams = 1:6,
                                     remove_punct = T,
                                     tolower = TRUE,
                                     stem = FALSE,
                                     select = NULL,
                                     remove = NULL,
                                     dictionary = NULL,
                                     thesaurus = NULL,
                                     groups = NULL)
```

```{r, echo=FALSE}
AFMC_dfm6 = readRDS(file.path(rprojroot::find_package_root_file(),"objs/AFMC_dfm6_2.R"))
```

## Step 3: Visualization {.tabset}

Considering the object `AFMC_dfm6`, we now demonstrate how a user would analyze the survey responses.  As was done by the AFMC analysts, our focus in this analysis is the first survey question:

> What is a "good" working environment and how would that differ from your current work environment?

Our analytical approach is summarized as follows

- The survey asks respondents to describe improvements or ways to improve some aspect of AFMC
- The responses include statements identifying both positive and negative trends 
- Respondents state they want to see an increased trend of positives and a decreasing trend of negatives
- Respondents use certain phrases in the course of stating these trends
- Our analysis identifies these phrases and along with the object to which they are applied

In the code chunks contained in the tabs below we generate word clouds illustrating the most common phrases starting with one-word phrases and ending with six-word phrases.  

### 1-Word Phrases

We first look at 1-word phrases (unigrams). The code below extracts the first element from the `AFMC_dfm6` object we create above and subsets this object to include only those responses for question 1 that were obtained as part of the field survey.

```{r, fig.width=10, cache=TRUE}
AFMC_dfm6_Q1_1 = AFMC_dfm6[[1]]

AFMC_dfm6_Q1_1 = quanteda::dfm_subset(AFMC_dfm6_Q1_1, 
                                      subset = Question == 1 & Source == "Field Survey")
```

Next, we build a table containing each unigram and its frequency and sort the table in descending order showing which unigrams were used most frequently.

```{r}
freq <- Matrix::colSums(AFMC_dfm6_Q1_1)
word <- names(freq)
freq <- unname(freq)
ord <- order(freq, decreasing = T)
word <- word[ord]
freq <- freq[ord]

df1 <- data.frame(term = word, frequency = freq) 

DT::datatable(df1[1:100,])
```

Then, I create a visual representation of the most frequently used unigrams.

```{r, out.width="100%"}
AFMC_dfm6_Q1_trim = quanteda::dfm_trim(AFMC_dfm6_Q1_1, 
                                       min_termfreq = 100,
                                       max_termfreq = 500)

quanteda::textplot_wordcloud(AFMC_dfm6_Q1_trim, max_words = 200)
```

```{r, out.width="100%"}
AFMC_dfm6_Q1_1 = quanteda::dfm_remove(AFMC_dfm6_Q1_1, pattern = tidytext::stop_words[[1]])

freq <- Matrix::colSums(AFMC_dfm6_Q1_1)
word <- names(freq)
freq <- unname(freq)
ord <- order(freq, decreasing = T)
word <- word[ord]
freq <- freq[ord]

df1 <- data.frame(term = word, frequency = freq) 

DT::datatable(df1[1:100,])

AFMC_dfm6_Q1_trim = quanteda::dfm_trim(AFMC_dfm6_Q1_1, 
                                       min_termfreq = 100,
                                       max_termfreq = 500)

quanteda::textplot_wordcloud(AFMC_dfm6_Q1_trim, max_words = 200)
```

#### Comparing Bases

It may be of interest to see the from which base these responses were received. The bar plot below shows that the largest group of responses were received from respondents that did not provide a base entry.  The remaining responses were dominated by Wright-Patterson AFB, and the three depots: Robins AFB, Tinker AFB, and Hill AFB.

```{r, out.width="100%", fig.cap="Barplot of AFMC We Need survey data showing the arrangement of repsonses by Base to Question 1 of the Field Survey."}
barplot(table(AFMC_dfm6_Q1_1@docvars$Base), 
        col = rainbow(length(unique(AFMC_dfm6_Q1_1@docvars$Base))),
        las = 1,
        xlab = "Base",
        ylab = "# of Responses")
```

The plot below presents three word clouds showing the most common one-word phrases received for  Question 1 of the Field Survey from each of the three depot bases.

```{r}
Tinker_dfm6_Q1_1 = quanteda::dfm_subset(AFMC_dfm6_Q1_1, 
                                        subset = Base == "Tinker")

Robins_dfm6_Q1_1 = quanteda::dfm_subset(AFMC_dfm6_Q1_1, 
                                        subset = Base == "Robins")

Hill_dfm6_Q1_1 = quanteda::dfm_subset(AFMC_dfm6_Q1_1, 
                                      subset = Base == "Hill")
```

```{r, echo=FALSE, out.width="80%", fig.cap="Wordcloud showing the 200 most used 1-word phrases from respondents at Tinker AFB for Question 1 on the Field Survey"}
quanteda::textplot_wordcloud(Tinker_dfm6_Q1_1, max_words = 200)
```

```{r, echo=FALSE, out.width="80%", fig.cap="Wordcloud showing the 200 most used 1-word phrases from respondents at Robins AFB for Question 1 on the Field Survey"}
quanteda::textplot_wordcloud(Robins_dfm6_Q1_1, max_words = 200)
```

```{r, echo=FALSE, out.width="80%", fig.cap="Wordcloud showing the 200 most used 1-word phrases from respondents at Hill AFB for Question 1 on the Field Survey"}
quanteda::textplot_wordcloud(Hill_dfm6_Q1_1, max_words = 200)
```

Each of these look very similar

### 2-Word Phrases

```{r, out.width="100%", cache=TRUE, echo=FALSE, eval=!quick}
AFMC_dfm6_Q1_2 = quanteda::dfm_subset(AFMC_dfm6[[2]], 
                                      subset = Question == 1 & Source == "Field Survey")

freq <- Matrix::colSums(AFMC_dfm6_Q1_2)
word <- names(freq)
freq <- unname(freq)
ord <- order(freq, decreasing = T)
word <- word[ord]
freq <- freq[ord]

df2 <- data.frame(term = word, frequency = freq) 

DT::datatable(df2[1:100,])

AFMC_dfm6_Q1_trim = quanteda::dfm_trim(AFMC_dfm6_Q1_2, 
                                       min_termfreq = 10,
                                       max_termfreq = 500)
```

```{r}
quanteda::textplot_wordcloud(AFMC_dfm6_Q1_trim, max_words = 150)
```

```{r}
Tinker_dfm6_Q1_2 = quanteda::dfm_subset(AFMC_dfm6_Q1_2, 
                                        subset = Base == "Tinker")

Robins_dfm6_Q1_2 = quanteda::dfm_subset(AFMC_dfm6_Q1_2, 
                                        subset = Base == "Robins")

Hill_dfm6_Q1_2 = quanteda::dfm_subset(AFMC_dfm6_Q1_2, 
                                      subset = Base == "Hill")
```

```{r, echo=FALSE, out.width="80%", fig.cap="Wordcloud showing the 200 most used 2-word phrases from respondents at Tinker AFB for Question 1 on the Field Survey"}
quanteda::textplot_wordcloud(Tinker_dfm6_Q1_2, max_words = 200)
```

```{r, echo=FALSE, out.width="80%", fig.cap="Wordcloud showing the 200 most used 2-word phrases from respondents at Robins AFB for Question 1 on the Field Survey"}
quanteda::textplot_wordcloud(Robins_dfm6_Q1_2, max_words = 200)
```

```{r, echo=FALSE, out.width="80%", fig.cap="Wordcloud showing the 200 most used 2-word phrases from respondents at Hill AFB for Question 1 on the Field Survey"}
quanteda::textplot_wordcloud(Hill_dfm6_Q1_2, max_words = 200)
```

### 3-Word Phrases

```{r, out.width="100%", cache=TRUE, echo=FALSE, eval=!quick}
AFMC_dfm6_Q1_3 = quanteda::dfm_subset(AFMC_dfm6[[3]], 
                                      subset = Question == 1 & Source == "Field Survey")

freq <- Matrix::colSums(AFMC_dfm6_Q1_3)
word <- names(freq)
freq <- unname(freq)
ord <- order(freq, decreasing = T)
word <- word[ord]
freq <- freq[ord]

df3 <- data.frame(term = word, frequency = freq) 

DT::datatable(df3[1:100,])

AFMC_dfm6_Q1_trim = quanteda::dfm_trim(AFMC_dfm6_Q1_3, 
                                       min_termfreq = 10,
                                       max_termfreq = 1000)
```

```{r}
quanteda::textplot_wordcloud(AFMC_dfm6_Q1_trim, max_words = 100)
```

```{r}
Tinker_dfm6_Q1_3 = quanteda::dfm_subset(AFMC_dfm6_Q1_3, 
                                        subset = Base == "Tinker")

Robins_dfm6_Q1_3 = quanteda::dfm_subset(AFMC_dfm6_Q1_3, 
                                        subset = Base == "Robins")

Hill_dfm6_Q1_3 = quanteda::dfm_subset(AFMC_dfm6_Q1_3, 
                                      subset = Base == "Hill")
```

```{r, echo=FALSE, out.width="80%", fig.cap="Wordcloud showing the 200 most used 3-word phrases from respondents at Tinker AFB for Question 1 on the Field Survey"}
quanteda::textplot_wordcloud(Tinker_dfm6_Q1_3, max_words = 200)
```

```{r, echo=FALSE, out.width="80%", fig.cap="Wordcloud showing the 200 most used 2-word phrases from respondents at Robins AFB for Question 1 on the Field Survey"}
quanteda::textplot_wordcloud(Robins_dfm6_Q1_3, max_words = 200)
```

```{r, echo=FALSE, out.width="80%", fig.cap="Wordcloud showing the 200 most used 2-word phrases from respondents at Hill AFB for Question 1 on the Field Survey"}
quanteda::textplot_wordcloud(Hill_dfm6_Q1_3, max_words = 200)
```

### 4-Word Phrases

```{r, out.width="100%", cache=TRUE, echo=FALSE, eval=!quick}
AFMC_dfm6_Q1_4 = quanteda::dfm_subset(AFMC_dfm6[[4]], 
                                      subset = Question == 1 & Source == "Field Survey")

freq <- Matrix::colSums(AFMC_dfm6_Q1_4)
word <- names(freq)
freq <- unname(freq)
ord <- order(freq, decreasing = T)
word <- word[ord]
freq <- freq[ord]

df4 <- data.frame(term = word, frequency = freq) 

DT::datatable(df4[1:100,])

AFMC_dfm6_Q1_trim = quanteda::dfm_trim(AFMC_dfm6_Q1_4, 
                                       min_termfreq = 10,
                                       max_termfreq = 1000)
```

```{r}
quanteda::textplot_wordcloud(AFMC_dfm6_Q1_trim, max_words = 75)
```

### 5-Word Phrases

```{r, out.width="100%", cache=TRUE, echo=FALSE, eval=!quick}
AFMC_dfm6_Q1_5 = quanteda::dfm_subset(AFMC_dfm6[[5]], 
                                      subset = Question == 1 & Source == "Field Survey")

freq <- Matrix::colSums(AFMC_dfm6_Q1_5)
word <- names(freq)
freq <- unname(freq)
ord <- order(freq, decreasing = T)
word <- word[ord]
freq <- freq[ord]

df5 <- data.frame(term = word, frequency = freq) 

DT::datatable(df5[1:100,])

AFMC_dfm6_Q1_trim = quanteda::dfm_trim(AFMC_dfm6_Q1_5, 
                                       min_termfreq = 10,
                                       max_termfreq = 100)
```

```{r}
quanteda::textplot_wordcloud(AFMC_dfm6_Q1_trim, max_words = 60)
```

### 6-Word Phrases

```{r, out.width="100%", cache=TRUE, echo=FALSE, eval=!quick}
AFMC_dfm6_Q1_6 = quanteda::dfm_subset(AFMC_dfm6[[6]], 
                                      subset = Question == 1 & Source == "Field Survey")

freq <- Matrix::colSums(AFMC_dfm6_Q1_6)
word <- names(freq)
freq <- unname(freq)
ord <- order(freq, decreasing = T)
word <- word[ord]
freq <- freq[ord]

df6 <- data.frame(term = word, frequency = freq) 

DT::datatable(df6[1:100,])

AFMC_dfm6_Q1_trim = quanteda::dfm_trim(AFMC_dfm6_Q1_6, 
                                       min_termfreq = 5,
                                       max_termfreq = 100)
```

```{r}
quanteda::textplot_wordcloud(AFMC_dfm6_Q1_trim, max_words = 50)
```

```{r}
Tinker_dfm6_Q1_6 = quanteda::dfm_subset(AFMC_dfm6_Q1_6, 
                                        subset = Base == "Tinker")

Robins_dfm6_Q1_6 = quanteda::dfm_subset(AFMC_dfm6_Q1_6, 
                                        subset = Base == "Robins")

Hill_dfm6_Q1_6 = quanteda::dfm_subset(AFMC_dfm6_Q1_6, 
                                      subset = Base == "Hill")
```

```{r, echo=FALSE, out.width="80%", fig.cap="Wordcloud showing the 200 most used 3-word phrases from respondents at Tinker AFB for Question 1 on the Field Survey"}
quanteda::textplot_wordcloud(Tinker_dfm6_Q1_6, max_words = 200)
```

```{r, echo=FALSE, out.width="80%", fig.cap="Wordcloud showing the 200 most used 2-word phrases from respondents at Robins AFB for Question 1 on the Field Survey"}
quanteda::textplot_wordcloud(Robins_dfm6_Q1_6, max_words = 200)
```

```{r, echo=FALSE, out.width="80%", fig.cap="Wordcloud showing the 200 most used 2-word phrases from respondents at Hill AFB for Question 1 on the Field Survey"}
quanteda::textplot_wordcloud(Hill_dfm6_Q1_6, max_words = 200)
```

```{r, eval=FALSE}
kwic(toks, pattern = phrase(multiword))
```

```{r,eval=FALSE}
  tidy_out1 %>%
    top_n(10) %>%
    ungroup() %>%
    mutate(bigram = reorder(term, count)) %>%
    ggplot(aes(bigram, count, fill = count)) +
    geom_col(show.legend = FALSE) +
    labs(y = "Mentions",
         x = NULL) +
    coord_flip()
```



